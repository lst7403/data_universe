{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from graph_tree_link_module import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv(r'../Data/train.csv')\n",
    "# print(raw)\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "# print(list(raw.columns)[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 14)\n",
      "['Popularity', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_in min/ms', 'time_signature']\n"
     ]
    }
   ],
   "source": [
    "data = raw.iloc[:,2:-1]\n",
    "data = data.fillna(0)\n",
    "data = data[:2000]\n",
    "print(data.shape)\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = scaler.fit_transform(data)\n",
    "\n",
    "# label\n",
    "y = raw.iloc[:,-1]\n",
    "# print(y)\n",
    "\n",
    "col_name = list(raw.columns)[2:-1]\n",
    "print(col_name)\n",
    "# print(normalized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_min = scaler.data_min_\n",
    "data_max = scaler.data_max_\n",
    "\n",
    "# print(data_min, data_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_query_generator():\n",
    "    return [random.uniform(data_min[i], data_max[i]) for i in range(len(data_max))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(31.016805846839198), np.float64(0.7291278423356826), np.float64(0.24147426922388437), np.float64(5.331519915598523), np.float64(-2.8552650708117753), np.float64(0.6525964137617971), np.float64(0.10845424067186216), np.float64(0.9645368391954534), np.float64(0.2232042816584578), np.float64(0.6178356824439832), np.float64(0.3009444075232025), np.float64(163.22372485514902), np.float64(871416.2469655385), np.float64(1.7102007994855901)]\n"
     ]
    }
   ],
   "source": [
    "print(test_query_generator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class Timer:\n",
    "    def __enter__(self):\n",
    "        self.start_time = time.perf_counter()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self.end_time = time.perf_counter()\n",
    "        self.elapsed_time = self.end_time - self.start_time\n",
    "        print(f\"Elapsed time: {self.elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------- level 0 no of node 1 ----------------------------------------\n",
      "queue:  [0]\n",
      "cur node 0\n",
      "no. of cur node data 2000\n",
      "optimal K 2\n",
      "\n",
      "\n",
      "---------------------------------- level 1 no of node 2 ----------------------------------------\n",
      "queue:  [1, 2]\n",
      "cur node 1\n",
      "no. of cur node data 719\n",
      "optimal K 4\n",
      "\n",
      "cur node 2\n",
      "no. of cur node data 1281\n",
      "optimal K 2\n",
      "\n",
      "\n",
      "---------------------------------- level 2 no of node 6 ----------------------------------------\n",
      "queue:  [3, 4, 5, 6, 7, 8]\n",
      "cur node 3\n",
      "no. of cur node data 238\n",
      "optimal K 2\n",
      "\n",
      "cur node 4\n",
      "no. of cur node data 277\n",
      "optimal K 3\n",
      "\n",
      "cur node 5\n",
      "no. of cur node data 78\n",
      "added to Popularity min\n",
      "added to danceability min\n",
      "added to energy max\n",
      "added to key max\n",
      "added to loudness max\n",
      "added to mode min\n",
      "added to speechiness min\n",
      "added to acousticness min\n",
      "added to instrumentalness max\n",
      "added to liveness min\n",
      "added to valence min\n",
      "added to tempo max\n",
      "added to duration_in min/ms max\n",
      "added to time_signature min\n",
      "cur node 6\n",
      "no. of cur node data 126\n",
      "added to energy min\n",
      "added to key max\n",
      "added to loudness min\n",
      "added to mode min\n",
      "added to speechiness min\n",
      "added to acousticness max\n",
      "added to liveness min\n",
      "added to tempo min\n",
      "added to duration_in min/ms min\n",
      "added to time_signature min\n",
      "cur node 7\n",
      "no. of cur node data 345\n",
      "optimal K 2\n",
      "\n",
      "cur node 8\n",
      "no. of cur node data 936\n",
      "optimal K 3\n",
      "\n",
      "\n",
      "---------------------------------- level 3 no of node 10 ----------------------------------------\n",
      "queue:  [9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "cur node 9\n",
      "no. of cur node data 133\n",
      "added to Popularity max\n",
      "added to danceability max\n",
      "added to key max\n",
      "added to loudness max\n",
      "added to mode min\n",
      "added to speechiness max\n",
      "added to instrumentalness min\n",
      "added to valence max\n",
      "added to time_signature max\n",
      "cur node 10\n",
      "no. of cur node data 105\n",
      "added to Popularity max\n",
      "added to danceability min\n",
      "added to energy max\n",
      "added to key max\n",
      "added to loudness max\n",
      "added to mode min\n",
      "added to acousticness min\n",
      "added to liveness max\n",
      "added to valence min\n",
      "cur node 11\n",
      "no. of cur node data 124\n",
      "added to danceability min\n",
      "added to energy max\n",
      "added to key min\n",
      "added to loudness max\n",
      "added to mode min\n",
      "added to acousticness min\n",
      "added to liveness max\n",
      "added to tempo max\n",
      "cur node 12\n",
      "no. of cur node data 55\n",
      "added to Popularity min\n",
      "added to key min\n",
      "added to mode min\n",
      "cur node 13\n",
      "no. of cur node data 98\n",
      "added to mode min\n",
      "added to valence max\n",
      "cur node 14\n",
      "no. of cur node data 88\n",
      "added to Popularity min\n",
      "added to danceability min\n",
      "added to energy min\n",
      "added to loudness min\n",
      "added to mode max\n",
      "added to speechiness min\n",
      "added to acousticness max\n",
      "added to instrumentalness max\n",
      "added to liveness min\n",
      "added to valence min\n",
      "added to tempo min\n",
      "added to duration_in min/ms min\n",
      "added to time_signature min\n",
      "cur node 15\n",
      "no. of cur node data 257\n",
      "optimal K 2\n",
      "\n",
      "cur node 16\n",
      "no. of cur node data 396\n",
      "optimal K 2\n",
      "\n",
      "cur node 17\n",
      "no. of cur node data 438\n",
      "optimal K 2\n",
      "\n",
      "cur node 18\n",
      "no. of cur node data 102\n",
      "added to mode max\n",
      "\n",
      "---------------------------------- level 4 no of node 6 ----------------------------------------\n",
      "queue:  [19, 20, 21, 22, 23, 24]\n",
      "cur node 19\n",
      "no. of cur node data 117\n",
      "added to mode max\n",
      "cur node 20\n",
      "no. of cur node data 140\n",
      "added to Popularity min\n",
      "added to mode max\n",
      "cur node 21\n",
      "no. of cur node data 197\n",
      "added to key min\n",
      "added to mode max\n",
      "cur node 22\n",
      "no. of cur node data 199\n",
      "added to Popularity max\n",
      "added to mode max\n",
      "cur node 23\n",
      "no. of cur node data 229\n",
      "optimal K 3\n",
      "\n",
      "cur node 24\n",
      "no. of cur node data 209\n",
      "optimal K 2\n",
      "\n",
      "\n",
      "---------------------------------- level 5 no of node 5 ----------------------------------------\n",
      "queue:  [25, 26, 27, 28, 29]\n",
      "cur node 25\n",
      "no. of cur node data 72\n",
      "added to Popularity min\n",
      "added to mode max\n",
      "cur node 26\n",
      "no. of cur node data 70\n",
      "added to Popularity max\n",
      "added to mode max\n",
      "added to instrumentalness min\n",
      "added to liveness min\n",
      "added to tempo min\n",
      "cur node 27\n",
      "no. of cur node data 87\n",
      "added to mode max\n",
      "added to liveness max\n",
      "added to valence max\n",
      "cur node 28\n",
      "no. of cur node data 127\n",
      "added to mode max\n",
      "added to valence min\n",
      "cur node 29\n",
      "no. of cur node data 82\n",
      "added to danceability min\n",
      "added to energy max\n",
      "added to loudness max\n",
      "added to mode max\n",
      "added to liveness max\n",
      "added to tempo max\n",
      "Elapsed time: 2.9847333999932744 seconds\n"
     ]
    }
   ],
   "source": [
    "test_tree = graph_tree(attr_name = col_name, X = normalized_data, X_maxmin=[scaler.data_max_,scaler.data_min_])\n",
    "# test_tree.show_root()\n",
    "with Timer():\n",
    "    test_tree.build_tree(min_threshold_for_clustering=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open(\"graph_tree.pkl\", 'wb') as f:\n",
    "#     pickle.dump(test_tree, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13069.980321083565\n"
     ]
    }
   ],
   "source": [
    "c = test_tree.root.center\n",
    "print(calculation.l1(test_tree.X(test_tree.root.index[0]), c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.0005437999789137393 seconds\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "t = 200000\n",
    "while t>100:\n",
    "    seaching = test_query_generator()\n",
    "    with Timer():\n",
    "        cur = test_tree.search(seaching)\n",
    "    t=cur.id\n",
    "    print(cur.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will return a sorted list of leaf node\n",
      "[14]\n",
      "poped 14\n",
      "cal True False\n",
      "[]\n",
      "[14]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "a = test_tree._get_closest_node_within_lv(seaching, cur)\n",
    "print([n.id for n in a])\n",
    "print(cur.down_lv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620402.1940225144\n",
      "620402.1940225144\n"
     ]
    }
   ],
   "source": [
    "print(calculation.l1(seaching, a[-1].center))\n",
    "print(calculation.l1(seaching, a[0].center))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "└── 0\n",
      "    ├── 1\n",
      "    │   ├── 3\n",
      "    │   │   ├── 9\n",
      "    │   │   └── 10\n",
      "    │   ├── 4\n",
      "    │   │   ├── 11\n",
      "    │   │   ├── 12\n",
      "    │   │   └── 13\n",
      "    │   ├── 5\n",
      "    │   └── 6\n",
      "    └── 2\n",
      "        ├── 7\n",
      "        │   ├── 14\n",
      "        │   └── 15\n",
      "        │       ├── 19\n",
      "        │       └── 20\n",
      "        └── 8\n",
      "            ├── 16\n",
      "            │   ├── 21\n",
      "            │   └── 22\n",
      "            ├── 17\n",
      "            │   ├── 23\n",
      "            │   │   ├── 25\n",
      "            │   │   ├── 26\n",
      "            │   │   └── 27\n",
      "            │   └── 24\n",
      "            │       ├── 28\n",
      "            │       └── 29\n",
      "            └── 18\n"
     ]
    }
   ],
   "source": [
    "test_tree.print_tree(test_tree.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "graph_tree.reflection_search() missing 1 required positional argument: 'degree'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mtest_tree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreflection_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalized_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_tree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: graph_tree.reflection_search() missing 1 required positional argument: 'degree'"
     ]
    }
   ],
   "source": [
    "res = test_tree.reflection_search(np.mean(normalized_data[:100], axis=0), test_tree.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(normalized_data.shape)\n",
    "print(np.mean(normalized_data[:100], axis=0))\n",
    "\n",
    "print(test_tree.root.center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\"\"\"\n",
    "create a new index (something like tf-idf)\n",
    "data reduction rate\n",
    "vs\n",
    "accurate\n",
    "\"\"\"\n",
    "def score(search_data, acc, smoothing = 0.001, lam = 0.5):\n",
    "    return lam*(acc/100)+(1-lam)*(1-(search_data/(1000+smoothing)))\n",
    "\n",
    "my_score = []\n",
    "normal_kmeans_score = []\n",
    "\n",
    "tmp = [i*100 for i in range(10)]\n",
    "for i in tmp:\n",
    "    b = i\n",
    "    u = i+100\n",
    "    # print(normalized_data[b:u])\n",
    "    print(f\"-- mine result{i}\")\n",
    "    seaching = np.mean(normalized_data[b:u], axis=0)\n",
    "    result = test_tree.search(seaching)\n",
    "    \n",
    "    print(\"search number: \", len(result.index))\n",
    "    right = np.where((result.index>=b) & (result.index<u))[0] # return index\n",
    "    print(\"hitted right result:\", len(right))\n",
    "    my_score.append(score(len(result.index), len(right)))\n",
    "\n",
    "    ############\n",
    "    print(\"-- kmeans result\")\n",
    "    checking = KMeans(n_clusters=10, random_state=0).fit(normalized_data)\n",
    "\n",
    "    counts1 = Counter(checking.labels_)\n",
    "    print(counts1)\n",
    "\n",
    "    counts2 = Counter(checking.labels_[b:u])\n",
    "    print(counts2)\n",
    "    belongs_group = counts2.most_common()[0][0]\n",
    "    print(\"belongs to group: \", belongs_group, \"\\n\")\n",
    "    # print(counts1.get(belongs_group), counts2.get(belongs_group))\n",
    "    normal_kmeans_score.append(score(counts1.get(belongs_group), counts2.get(belongs_group)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_score)\n",
    "print(normal_kmeans_score)\n",
    "\n",
    "print(sum(my_score))\n",
    "print(sum(normal_kmeans_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
