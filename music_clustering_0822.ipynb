{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# from sklearn.cluster import Birch\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means_model_with_best_sil_score(X, random_seed = 0, kmax = 10):\n",
    "  # sil = []\n",
    "\n",
    "  # for k in range(2, kmax+1):\n",
    "  #   kmeans = KMeans(n_clusters = k, random_state=random_seed).fit(X)\n",
    "  #   sil.append(silhouette_score(X, kmeans.labels_, metric = 'euclidean'))\n",
    "\n",
    "  # print(sil)\n",
    "  # return sil.index(max(sil))+2\n",
    "\n",
    "  highest_score = 0\n",
    "  k = 0\n",
    "  k_means_model = None\n",
    "\n",
    "  for ks in range(2, kmax+1):\n",
    "    kmeans = KMeans(n_clusters = ks, random_state=random_seed).fit(X)\n",
    "    cur_score = silhouette_score(X, kmeans.labels_, metric = 'euclidean')\n",
    "    if cur_score > highest_score:\n",
    "      highest_score = cur_score\n",
    "      k = ks\n",
    "      k_means_model = kmeans\n",
    "\n",
    "  return {\"k_means_model\": k_means_model, \"best_k\": k}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data structure\n",
    "class node:\n",
    "    def __init__(self, centre, index, up_lv = None, down_lv = None, far = 0):\n",
    "        self.centre = centre # cluster centre (vector)\n",
    "        self.index = index # cashe of search result, first 100? result close to centre (list of index)\n",
    "        self.up_lv = up_lv # super-cluster (node)\n",
    "        self.down_lv = down_lv # sub-cluster (lsit of node)\n",
    "        self.far = far # farest data in the cluster ( a boundary of the cluster) (value)\n",
    "\n",
    "# graph tree (cluster)\n",
    "class graph_tree:\n",
    "    def __init__(self, X):\n",
    "        self.X = X\n",
    "        self.root = node(np.mean(X, axis=0), np.array([i for i in range(len(X))]))\n",
    "        self.tree_deep = 0\n",
    "        print(\"root node is created\")\n",
    "\n",
    "    def sim(self, vector_1, vector_2):\n",
    "        return sum((vector_1-vector_2)**2)\n",
    "\n",
    "    def search(self, attribute, deep = 2):\n",
    "        # print(\"searching\")\n",
    "        cur = self.root\n",
    "        \n",
    "        while cur.down_lv:\n",
    "            old_cur = cur\n",
    "            cur_centre_distance = self.sim(attribute, cur.centre)\n",
    "            # print(cur_centre_distance)\n",
    "\n",
    "            closest = cur_centre_distance\n",
    "\n",
    "            for node in cur.down_lv:\n",
    "                if self.sim(attribute, node.centre) < closest:\n",
    "                    closest = self.sim(attribute, node.centre)\n",
    "                    cur = node\n",
    "\n",
    "\n",
    "            # search_node_queue = [cur]\n",
    "            # # normal search with only center counting\n",
    "            # for layer in range(deep):\n",
    "            #     print(search_node_queue)\n",
    "            #     size = len(search_node_queue)\n",
    "            #     for i in range(size):\n",
    "            #         searching_node = search_node_queue.pop(0)\n",
    "            #         if searching_node.down_lv:\n",
    "            #             for node in searching_node.down_lv:\n",
    "            #                 if self.sim(attribute, node.centre) < closest:\n",
    "            #                     closest = self.sim(attribute, node.centre)\n",
    "            #                     cur = node\n",
    "            #                 # add down lv node into the queue\n",
    "            #                 if node.down_lv:\n",
    "            #                     search_node_queue += node.down_lv\n",
    "                            \n",
    "\n",
    "            # boundary search by considering the cluster boundary (far attr)\n",
    "            if cur == old_cur:\n",
    "                for node in cur.down_lv:\n",
    "                    if self.sim(attribute, node.centre)-cur.far < closest:\n",
    "                        closest = self.sim(attribute, node.centre)\n",
    "                        cur = node\n",
    "            \n",
    "            \n",
    "            if cur == old_cur:\n",
    "                break\n",
    "\n",
    "        return cur\n",
    "        \n",
    "    def build_tree(self):\n",
    "        queue = []\n",
    "        queue.append(self.root)\n",
    "        \n",
    "        lv = 0\n",
    "    \n",
    "        while queue:\n",
    "            print(\"queue\", queue)\n",
    "            size = len(queue)\n",
    "            print(f\"\\n---------------------------------- level {lv} no of node {size} ----------------------------------------\")\n",
    "            for node_in_this_lv in range(size):\n",
    "                print(f\"\\nhandling node {node_in_this_lv}, info:\")\n",
    "                # k means required parameter and train the model\n",
    "                cur = queue.pop(0) # get cur node\n",
    "                cur_X = self.X[cur.index] # get cur data by index\n",
    "                k_means_model = k_means_model_with_best_sil_score(cur_X) # get kmeans model\n",
    "\n",
    "                print(f\"cur node {cur}\")\n",
    "                print(f\"no. of cur node data {len(cur_X)}\")\n",
    "                print(\"optimal K\", k_means_model[\"best_k\"], \"\\n\")\n",
    "\n",
    "                cur_kmeans = k_means_model[\"k_means_model\"] # best k means model\n",
    "\n",
    "                new_down_lv = []\n",
    "                for groups in range(k_means_model[\"best_k\"]):\n",
    "                    print(f\"creating node {groups}\")\n",
    "                    new_index_of_index = np.where(cur_kmeans.labels_ == groups)[0]\n",
    "\n",
    "                    # calculate the farest distance\n",
    "                    data_in_this_gp  = self.X[cur.index[new_index_of_index]]\n",
    "                    farest_distance = np.max(np.sum((data_in_this_gp - cur_kmeans.cluster_centers_[groups])**2, axis=1))\n",
    "\n",
    "                    new_node = node(cur_kmeans.cluster_centers_[groups], cur.index[new_index_of_index], up_lv=cur, far=farest_distance)\n",
    "\n",
    "                    new_down_lv.append(new_node)\n",
    "                    print(f\"new node {new_node}\")\n",
    "                    # print(\"new node centre\", new_node.centre)\n",
    "                    print(f\"no. of new node data {len(new_node.index)}\")\n",
    "                    print(f\"down lv of this node {new_down_lv}\")\n",
    "                    \n",
    "                    # least no. of data\n",
    "                    if len(new_index_of_index) >= 185:\n",
    "                        queue.append(new_node)\n",
    "                \n",
    "                cur.down_lv = new_down_lv\n",
    "                \n",
    "\n",
    "            lv += 1\n",
    "\n",
    "            self.tree_deep = lv+1\n",
    "\n",
    "        return 0\n",
    "    \n",
    "    # def print_tree(self, level = None):\n",
    "    #     level = level if level else self.tree_deep\n",
    "    #     queue = [self.root]\n",
    "    #     for t in range(level):\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv(r'Data\\features_30_sec.csv')\n",
    "raw\n",
    "\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw.iloc[:,1:-1]\n",
    "data\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = scaler.fit_transform(data)\n",
    "\n",
    "y = raw.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root node is created\n",
      "queue [<__main__.node object at 0x0000026E82B90590>]\n",
      "\n",
      "---------------------------------- level 0 no of node 1 ----------------------------------------\n",
      "\n",
      "handling node 0, info:\n",
      "cur node <__main__.node object at 0x0000026E82B90590>\n",
      "no. of cur node data 1000\n",
      "optimal K 3 \n",
      "\n",
      "creating node 0\n",
      "new node <__main__.node object at 0x0000026ED3148F90>\n",
      "no. of new node data 353\n",
      "down lv of this node [<__main__.node object at 0x0000026ED3148F90>]\n",
      "creating node 1\n",
      "new node <__main__.node object at 0x0000026E82B9C950>\n",
      "no. of new node data 318\n",
      "down lv of this node [<__main__.node object at 0x0000026ED3148F90>, <__main__.node object at 0x0000026E82B9C950>]\n",
      "creating node 2\n",
      "new node <__main__.node object at 0x0000026E82B93290>\n",
      "no. of new node data 329\n",
      "down lv of this node [<__main__.node object at 0x0000026ED3148F90>, <__main__.node object at 0x0000026E82B9C950>, <__main__.node object at 0x0000026E82B93290>]\n",
      "queue [<__main__.node object at 0x0000026ED3148F90>, <__main__.node object at 0x0000026E82B9C950>, <__main__.node object at 0x0000026E82B93290>]\n",
      "\n",
      "---------------------------------- level 1 no of node 3 ----------------------------------------\n",
      "\n",
      "handling node 0, info:\n",
      "cur node <__main__.node object at 0x0000026ED3148F90>\n",
      "no. of cur node data 353\n",
      "optimal K 2 \n",
      "\n",
      "creating node 0\n",
      "new node <__main__.node object at 0x0000026E828BEE50>\n",
      "no. of new node data 183\n",
      "down lv of this node [<__main__.node object at 0x0000026E828BEE50>]\n",
      "creating node 1\n",
      "new node <__main__.node object at 0x0000026E826C3B90>\n",
      "no. of new node data 170\n",
      "down lv of this node [<__main__.node object at 0x0000026E828BEE50>, <__main__.node object at 0x0000026E826C3B90>]\n",
      "\n",
      "handling node 1, info:\n",
      "cur node <__main__.node object at 0x0000026E82B9C950>\n",
      "no. of cur node data 318\n",
      "optimal K 2 \n",
      "\n",
      "creating node 0\n",
      "new node <__main__.node object at 0x0000026E82B90850>\n",
      "no. of new node data 203\n",
      "down lv of this node [<__main__.node object at 0x0000026E82B90850>]\n",
      "creating node 1\n",
      "new node <__main__.node object at 0x0000026E825EBDD0>\n",
      "no. of new node data 115\n",
      "down lv of this node [<__main__.node object at 0x0000026E82B90850>, <__main__.node object at 0x0000026E825EBDD0>]\n",
      "\n",
      "handling node 2, info:\n",
      "cur node <__main__.node object at 0x0000026E82B93290>\n",
      "no. of cur node data 329\n",
      "optimal K 2 \n",
      "\n",
      "creating node 0\n",
      "new node <__main__.node object at 0x0000026E82B9DC90>\n",
      "no. of new node data 141\n",
      "down lv of this node [<__main__.node object at 0x0000026E82B9DC90>]\n",
      "creating node 1\n",
      "new node <__main__.node object at 0x0000026E82B9B390>\n",
      "no. of new node data 188\n",
      "down lv of this node [<__main__.node object at 0x0000026E82B9DC90>, <__main__.node object at 0x0000026E82B9B390>]\n",
      "queue [<__main__.node object at 0x0000026E82B90850>, <__main__.node object at 0x0000026E82B9B390>]\n",
      "\n",
      "---------------------------------- level 2 no of node 2 ----------------------------------------\n",
      "\n",
      "handling node 0, info:\n",
      "cur node <__main__.node object at 0x0000026E82B90850>\n",
      "no. of cur node data 203\n",
      "optimal K 2 \n",
      "\n",
      "creating node 0\n",
      "new node <__main__.node object at 0x0000026E82A8D090>\n",
      "no. of new node data 109\n",
      "down lv of this node [<__main__.node object at 0x0000026E82A8D090>]\n",
      "creating node 1\n",
      "new node <__main__.node object at 0x0000026E82B98810>\n",
      "no. of new node data 94\n",
      "down lv of this node [<__main__.node object at 0x0000026E82A8D090>, <__main__.node object at 0x0000026E82B98810>]\n",
      "\n",
      "handling node 1, info:\n",
      "cur node <__main__.node object at 0x0000026E82B9B390>\n",
      "no. of cur node data 188\n",
      "optimal K 2 \n",
      "\n",
      "creating node 0\n",
      "new node <__main__.node object at 0x0000026E82A6B550>\n",
      "no. of new node data 88\n",
      "down lv of this node [<__main__.node object at 0x0000026E82A6B550>]\n",
      "creating node 1\n",
      "new node <__main__.node object at 0x0000026E82BC0D50>\n",
      "no. of new node data 100\n",
      "down lv of this node [<__main__.node object at 0x0000026E82A6B550>, <__main__.node object at 0x0000026E82BC0D50>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tree = graph_tree(normalized_data)\n",
    "# test_tree.show_root()\n",
    "test_tree.build_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 58)\n",
      "[0.11348684 0.34466932 0.72605349 0.33305741 0.10877244 0.29947823\n",
      " 0.09304523 0.39569181 0.15035941 0.36422083 0.17241909 0.22643159\n",
      " 0.05545706 0.62273814 0.15774551 0.50904565 0.09744436 0.36549813\n",
      " 0.65222521 0.12414806 0.59314374 0.13376623 0.56282273 0.16902846\n",
      " 0.65715205 0.21199967 0.50119821 0.17264277 0.68976559 0.2116002\n",
      " 0.40642335 0.28073522 0.52519319 0.19397631 0.37807936 0.22873911\n",
      " 0.51505091 0.19394156 0.40249091 0.10072538 0.49799014 0.18860505\n",
      " 0.47996194 0.18586443 0.45119759 0.10657799 0.3583135  0.13427742\n",
      " 0.54500148 0.14372898 0.34880168 0.13019081 0.38442208 0.16402178\n",
      " 0.44870923 0.14583445 0.48545943 0.12517942]\n",
      "[0.12846951 0.42042582 0.65744286 0.31997514 0.11010242 0.42216161\n",
      " 0.15245649 0.51481278 0.18463802 0.48210799 0.21161387 0.32386061\n",
      " 0.10260274 0.62498145 0.14590304 0.5221195  0.11949048 0.35862408\n",
      " 0.68609031 0.12730489 0.51920421 0.15606796 0.55235925 0.14981778\n",
      " 0.5533549  0.21443681 0.5366843  0.13712389 0.58499709 0.21667654\n",
      " 0.50771594 0.23316962 0.47391224 0.18117458 0.48541999 0.21445886\n",
      " 0.50378616 0.18646655 0.48454018 0.09515029 0.5219536  0.18086365\n",
      " 0.56013696 0.18603079 0.46720589 0.1048901  0.45725908 0.12747406\n",
      " 0.57775003 0.13435802 0.46203949 0.12419971 0.45595759 0.15210813\n",
      " 0.48719019 0.13891985 0.53356035 0.12481117]\n"
     ]
    }
   ],
   "source": [
    "print(normalized_data.shape)\n",
    "print(np.mean(normalized_data[:100], axis=0))\n",
    "\n",
    "print(test_tree.root.centre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- mine result 0\n",
      "search number:  1000\n",
      "hitted right result: 100\n",
      "-- kmeans result\n",
      "Counter({5: 219, 9: 126, 0: 125, 3: 120, 2: 109, 4: 84, 6: 69, 8: 66, 1: 51, 7: 31})\n",
      "Counter({5: 30, 9: 22, 0: 20, 7: 18, 4: 8, 6: 2})\n",
      "belongs to group:  5 \n",
      "\n",
      "-- mine result 100\n",
      "search number:  170\n",
      "hitted right result: 95\n",
      "-- kmeans result\n",
      "Counter({5: 219, 9: 126, 0: 125, 3: 120, 2: 109, 4: 84, 6: 69, 8: 66, 1: 51, 7: 31})\n",
      "Counter({6: 49, 9: 47, 0: 2, 3: 1, 2: 1})\n",
      "belongs to group:  6 \n",
      "\n",
      "-- mine result 200\n",
      "search number:  1000\n",
      "hitted right result: 100\n",
      "-- kmeans result\n",
      "Counter({5: 219, 9: 126, 0: 125, 3: 120, 2: 109, 4: 84, 6: 69, 8: 66, 1: 51, 7: 31})\n",
      "Counter({0: 28, 2: 19, 9: 19, 3: 14, 7: 8, 5: 7, 4: 5})\n",
      "belongs to group:  0 \n",
      "\n",
      "-- mine result 300\n",
      "search number:  1000\n",
      "hitted right result: 100\n",
      "-- kmeans result\n",
      "Counter({5: 219, 9: 126, 0: 125, 3: 120, 2: 109, 4: 84, 6: 69, 8: 66, 1: 51, 7: 31})\n",
      "Counter({3: 33, 5: 32, 0: 13, 2: 11, 4: 8, 8: 2, 6: 1})\n",
      "belongs to group:  3 \n",
      "\n",
      "-- mine result 400\n",
      "search number:  1000\n",
      "hitted right result: 100\n",
      "-- kmeans result\n",
      "Counter({5: 219, 9: 126, 0: 125, 3: 120, 2: 109, 4: 84, 6: 69, 8: 66, 1: 51, 7: 31})\n",
      "Counter({5: 23, 8: 23, 4: 20, 1: 15, 2: 11, 3: 6, 0: 2})\n",
      "belongs to group:  5 \n",
      "\n",
      "-- mine result 500\n",
      "search number:  170\n",
      "hitted right result: 54\n",
      "-- kmeans result\n",
      "Counter({5: 219, 9: 126, 0: 125, 3: 120, 2: 109, 4: 84, 6: 69, 8: 66, 1: 51, 7: 31})\n",
      "Counter({9: 30, 0: 27, 3: 16, 6: 14, 2: 11, 5: 1, 7: 1})\n",
      "belongs to group:  9 \n",
      "\n",
      "-- mine result 600\n",
      "search number:  141\n",
      "hitted right result: 79\n",
      "-- kmeans result\n",
      "Counter({5: 219, 9: 126, 0: 125, 3: 120, 2: 109, 4: 84, 6: 69, 8: 66, 1: 51, 7: 31})\n",
      "Counter({5: 90, 0: 5, 3: 3, 4: 2})\n",
      "belongs to group:  5 \n",
      "\n",
      "-- mine result 700\n",
      "search number:  115\n",
      "hitted right result: 54\n",
      "-- kmeans result\n",
      "Counter({5: 219, 9: 126, 0: 125, 3: 120, 2: 109, 4: 84, 6: 69, 8: 66, 1: 51, 7: 31})\n",
      "Counter({1: 32, 8: 28, 3: 23, 2: 13, 6: 2, 7: 2})\n",
      "belongs to group:  1 \n",
      "\n",
      "-- mine result 800\n",
      "search number:  1000\n",
      "hitted right result: 100\n",
      "-- kmeans result\n",
      "Counter({5: 219, 9: 126, 0: 125, 3: 120, 2: 109, 4: 84, 6: 69, 8: 66, 1: 51, 7: 31})\n",
      "Counter({4: 36, 2: 29, 8: 13, 0: 4, 9: 4, 3: 4, 1: 4, 5: 3, 7: 2, 6: 1})\n",
      "belongs to group:  4 \n",
      "\n",
      "-- mine result 900\n",
      "search number:  1000\n",
      "hitted right result: 100\n",
      "-- kmeans result\n",
      "Counter({5: 219, 9: 126, 0: 125, 3: 120, 2: 109, 4: 84, 6: 69, 8: 66, 1: 51, 7: 31})\n",
      "Counter({5: 33, 0: 24, 3: 20, 2: 14, 4: 5, 9: 4})\n",
      "belongs to group:  5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\"\"\"\n",
    "create a new index (something like tf-idf)\n",
    "data reduction rate\n",
    "vs\n",
    "accurate\n",
    "\"\"\"\n",
    "def score(search_data, acc, smoothing = 0.001, lam = 0.5):\n",
    "    return lam*(acc/100)+(1-lam)*(1-(search_data/(1000+smoothing)))\n",
    "\n",
    "my_score = []\n",
    "normal_kmeans_score = []\n",
    "\n",
    "tmp = [i*100 for i in range(10)]\n",
    "for i in tmp:\n",
    "    b = i\n",
    "    u = i+100\n",
    "    # print(normalized_data[b:u])\n",
    "    print(f\"-- mine result {i}\")\n",
    "    seaching = np.mean(normalized_data[b:u], axis=0)\n",
    "    result = test_tree.search(seaching)\n",
    "    \n",
    "    print(\"search number: \", len(result.index))\n",
    "    right = np.where((result.index>=b) & (result.index<u))[0] # return index\n",
    "    print(\"hitted right result:\", len(right))\n",
    "    my_score.append(score(len(result.index), len(right)))\n",
    "\n",
    "    ############\n",
    "    print(\"-- kmeans result\")\n",
    "    checking = KMeans(n_clusters=10, random_state=0).fit(normalized_data)\n",
    "\n",
    "    counts1 = Counter(checking.labels_)\n",
    "    print(counts1)\n",
    "\n",
    "    counts2 = Counter(checking.labels_[b:u])\n",
    "    print(counts2)\n",
    "    belongs_group = counts2.most_common()[0][0]\n",
    "    print(\"belongs to group: \", belongs_group, \"\\n\")\n",
    "    # print(counts1.get(belongs_group), counts2.get(belongs_group))\n",
    "    normal_kmeans_score.append(score(counts1.get(belongs_group), counts2.get(belongs_group)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5000004999995, 0.890000084999915, 0.5000004999995, 0.5000004999995, 0.5000004999995, 0.685000084999915, 0.8245000704999295, 0.7125000574999425, 0.5000004999995, 0.5000004999995]\n",
      "[0.5405001094998905, 0.7105000344999655, 0.5775000624999376, 0.60500005999994, 0.5055001094998905, 0.587000062999937, 0.8405001094998905, 0.6345000254999745, 0.6380000419999581, 0.5555001094998905]\n",
      "6.112003297996701\n",
      "6.1945007254992746\n"
     ]
    }
   ],
   "source": [
    "print(my_score)\n",
    "print(normal_kmeans_score)\n",
    "\n",
    "print(sum(my_score))\n",
    "print(sum(normal_kmeans_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
